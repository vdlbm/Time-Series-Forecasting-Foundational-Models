{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import my_data_frequency_conversor as dfc\n",
    "import my_models as mm\n",
    "import my_llm_ts_preprocessor as tsp\n",
    "import my_prompting_tool as mpt \n",
    "\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing \n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import Holt\n",
    "\n",
    "from nixtla import NixtlaClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Carga el .env\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOURS = 'DATA/ETHUSD-H1.csv'\n",
    "DATA_DAYS = 'DATA/ETHUSD-D1.csv'\n",
    "DATA_MONTHS = 'DATA/ETHUSD-Monthly.csv'\n",
    "arima_h = mm.Model('ARIMA', 0, 0, 0)\n",
    "arima_d = mm.Model('ARIMA-d', 0, 0, 0)\n",
    "arima_m = mm.Model('ARIMA-m', 0, 0, 0)\n",
    "exp_smooth_h = mm.Model('EXPONENTIAL SMOOTHING', 0, 0, 0)\n",
    "exp_smooth_d = mm.Model('EXPONENTIAL SMOOTHING', 0, 0, 0)\n",
    "exp_smooth_m = mm.Model('EXPONENTIAL SMOOTHING', 0, 0, 0)\n",
    "holt_h = mm.Model('HOLT', 0, 0, 0)\n",
    "holt_d = mm.Model('HOLT', 0, 0, 0)\n",
    "holt_m = mm.Model('HOLT', 0, 0, 0)\n",
    "holt_winters_h = mm.Model('HOLT WINTERS', 0, 0, 0)\n",
    "holt_winters_d = mm.Model('HOLT WINTERS', 0, 0, 0)\n",
    "holt_winters_m = mm.Model('HOLT WINTERS', 0, 0, 0)\n",
    "timegpt_h = mm.Model('TIMEGPT', 0, 0, 0)\n",
    "timegpt_d = mm.Model('TIMEGPT', 0, 0, 0)\n",
    "timegpt_m = mm.Model('TIMEGPT', 0, 0, 0)\n",
    "lagllama_h = mm.Model('LAGLLAMA', 0, 0, 0)\n",
    "lagllama_d = mm.Model('LAGLLAMA', 0, 0, 0)\n",
    "lagllama_m = mm.Model('LAGLLAMA', 0, 0, 0)\n",
    "gpt_h = mm.Model('GPT-H', 0, 0, 0)\n",
    "gpt_d = mm.Model('GPT-D', 0, 0, 0)\n",
    "gpt_m = mm.Model('GPT-M', 0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_HOURS, delimiter=',')\n",
    "train_data_hours, val_data_hours = dfc.split_data(df)\n",
    "train_data_hours = train_data_hours.asfreq('h')\n",
    "val_data_hours = val_data_hours.asfreq('h')\n",
    "print(train_data_hours.head())\n",
    "print(val_data_hours.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una serie de ejemplo\n",
    "series = [0.123, 1.23, 12.3, 123.0, 1000.0]\n",
    "\n",
    "# Instanciar el preprocesador\n",
    "preprocessor = tsp.TimeSeriesPreprocessor(percentile=95)\n",
    "\n",
    "# Procesar la serie\n",
    "processed_series = preprocessor.preprocess(series)\n",
    "\n",
    "print(processed_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_DAYS, delimiter=',')\n",
    "train_data_days, val_data_days = dfc.split_data(df)\n",
    "train_data_days = train_data_days.asfreq('d')\n",
    "val_data_days = val_data_days.asfreq('d')\n",
    "print(train_data_days.head())\n",
    "print(val_data_days.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_months = pd.read_csv(DATA_MONTHS, delimiter=',')\n",
    "train_data_months, val_data_months = dfc.split_data(data_months)\n",
    "train_data_months = train_data_months.asfreq('MS')\n",
    "val_data_months = val_data_months.asfreq('MS')\n",
    "print(train_data_months.head())\n",
    "print(val_data_months.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la serie en DataFrame con las columnas correctas\n",
    "arima_m.nixtla_format = dfc.convert_to_nixtla(train_data_months)\n",
    "print(arima_m.nixtla_format.head())\n",
    "arima_m.model = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=1)],\n",
    "    freq='MS'\n",
    ")\n",
    "\n",
    "arima_m.model.fit(arima_m.nixtla_format)\n",
    "arima_m.forecast = arima_m.model.predict(h=12, level=[95])\n",
    "print(arima_m.forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA forecast against the actual data with the confidence intervals\n",
    "train_df = train_data_months.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "train_df.columns = ['ds', 'y']\n",
    "train_df['type'] = 'Train'\n",
    "\n",
    "val_df = val_data_months.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "val_df.columns = ['ds', 'y']  # Renombrar columnas\n",
    "val_df['type'] = 'Validation'\n",
    "\n",
    "# Concatenar los datos de entrenamiento y validación para graficar\n",
    "all_data = pd.concat([train_df, val_df])\n",
    "\n",
    "# Graficar los datos de entrenamiento y validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_data['ds'], all_data['y'], label='Datos Reales', color='blue')\n",
    "\n",
    "# Graficar las predicciones\n",
    "plt.plot(arima_m.forecast['ds'], arima_m.forecast['AutoARIMA'], label='Predicciones', color='red')\n",
    "\n",
    "# Graficar el intervalo de confianza\n",
    "plt.fill_between(\n",
    "    arima_m.forecast['ds'],\n",
    "    arima_m.forecast['AutoARIMA-lo-95'],\n",
    "    arima_m.forecast['AutoARIMA-hi-95'],\n",
    "    color='pink',\n",
    "    alpha=0.3,\n",
    "    label='Intervalo de Confianza 95%'\n",
    ")\n",
    "\n",
    "# Añadir leyenda y etiquetas\n",
    "plt.legend()\n",
    "plt.title('Predicciones vs Datos Reales')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Open')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_d.nixtla_format = dfc.convert_to_nixtla(train_data_days)\n",
    "print(arima_d.nixtla_format.head())\n",
    "arima_d.model = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=1)],\n",
    "    freq='D'\n",
    ")\n",
    "'''\n",
    "season_length=7:Se asume que hay un patrón semanal en los datos diarios. \n",
    "Si no es el caso, puedes cambiarlo a 1 (sin estacionalidad) o 365 (estacionalidad anual).\n",
    "'''\n",
    "arima_d.model.fit(arima_d.nixtla_format)\n",
    "arima_d.forecast = arima_d.model.predict(h=366, level=[95])\n",
    "print(arima_d.forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA forecast against the actual data with the confidence intervals\n",
    "train_df = train_data_days.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "train_df.columns = ['ds', 'y']\n",
    "train_df['type'] = 'Train'\n",
    "\n",
    "val_df = val_data_days.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "val_df.columns = ['ds', 'y']  # Renombrar columnas\n",
    "val_df['type'] = 'Validation'\n",
    "\n",
    "# Concatenar los datos de entrenamiento y validación para graficar\n",
    "all_data = pd.concat([train_df, val_df])\n",
    "\n",
    "# Graficar los datos de entrenamiento y validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_data['ds'], all_data['y'], label='Datos Reales', color='blue')\n",
    "\n",
    "# Graficar las predicciones\n",
    "plt.plot(arima_d.forecast['ds'], arima_d.forecast['AutoARIMA'], label='Predicciones', color='red')\n",
    "\n",
    "# Graficar el intervalo de confianza\n",
    "plt.fill_between(\n",
    "    arima_d.forecast['ds'],\n",
    "    arima_d.forecast['AutoARIMA-lo-95'],\n",
    "    arima_d.forecast['AutoARIMA-hi-95'],\n",
    "    color='pink',\n",
    "    alpha=0.3,\n",
    "    label='Intervalo de Confianza 95%'\n",
    ")\n",
    "\n",
    "# Añadir leyenda y etiquetas\n",
    "plt.legend()\n",
    "plt.title('Predicciones vs Datos Reales')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Open')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_h.nixtla_format = dfc.convert_to_nixtla(train_data_hours)\n",
    "print(arima_h.nixtla_format.head())\n",
    "arima_h.model = StatsForecast(\n",
    "    models=[AutoARIMA(season_length=24)],\n",
    "    freq='H'\n",
    ")\n",
    "'''\n",
    "season_length=24: Se asume que hay un patrón diario en los datos horarios.\n",
    "Si no es el caso, puedes cambiarlo a 1 (sin estacionalidad) o 168 (estacionalidad semanal).\n",
    "'''\n",
    "arima_h.model.fit(arima_h.nixtla_format)\n",
    "arima_h.forecast = arima_h.model.predict(h=24*366, level=[95])\n",
    "print(arima_h.forecast.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ARIMA forecast against the actual data with the confidence intervals\n",
    "train_df = train_data_hours.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "train_df.columns = ['ds', 'y']\n",
    "train_df['type'] = 'Train'\n",
    "\n",
    "val_df = val_data_hours.reset_index().iloc[:, :2]  # Solo tomar las dos primeras columnas\n",
    "val_df.columns = ['ds', 'y']  # Renombrar columnas\n",
    "val_df['type'] = 'Validation'\n",
    "\n",
    "# Concatenar los datos de entrenamiento y validación para graficar\n",
    "all_data = pd.concat([train_df, val_df])\n",
    "\n",
    "# Graficar los datos de entrenamiento y validación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(all_data['ds'], all_data['y'], label='Datos Reales', color='blue')\n",
    "\n",
    "# Graficar las predicciones\n",
    "plt.plot(arima_h.forecast['ds'], arima_h.forecast['AutoARIMA'], label='Predicciones', color='red')\n",
    "\n",
    "# Graficar el intervalo de confianza\n",
    "plt.fill_between(\n",
    "    arima_h.forecast['ds'],\n",
    "    arima_h.forecast['AutoARIMA-lo-95'],\n",
    "    arima_h.forecast['AutoARIMA-hi-95'],\n",
    "    color='pink',\n",
    "    alpha=0.3,\n",
    "    label='Intervalo de Confianza 95%'\n",
    ")\n",
    "\n",
    "# Añadir leyenda y etiquetas\n",
    "plt.legend()\n",
    "plt.title('Predicciones vs Datos Reales')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Open')\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha\n",
    "exp_smooth_m.model = SimpleExpSmoothing(train_data_months).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "exp_smooth_m.optimal_alpha = exp_smooth_m.model.model.params[\"smoothing_level\"]\n",
    "print(f\"Alpha óptimo: {exp_smooth_m.optimal_alpha:.4f}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "exp_smooth_m.forecast = exp_smooth_m.model.forecast(steps=12)\n",
    "exp_smooth_m.forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha\n",
    "exp_smooth_d.model = SimpleExpSmoothing(train_data_days).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "exp_smooth_d.optimal_alpha = exp_smooth_d.model.model.params[\"smoothing_level\"]\n",
    "print(f\"Alpha óptimo: {exp_smooth_d.optimal_alpha:.4f}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "exp_smooth_d.forecast = exp_smooth_d.model.forecast(steps=366)\n",
    "exp_smooth_d.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha\n",
    "exp_smooth_h.model = SimpleExpSmoothing(train_data_hours).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "exp_smooth_h.optimal_alpha = exp_smooth_h.model.model.params[\"smoothing_level\"]\n",
    "print(f\"Alpha óptimo: {exp_smooth_h.optimal_alpha:.4f}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "exp_smooth_h.forecast = exp_smooth_h.model.forecast(steps=366*24)\n",
    "exp_smooth_h.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_m.model = Holt(train_data_months).fit(optimized=True)\n",
    "holt_m.optimal_alpha = holt_m.model.model.params[\"smoothing_level\"]\n",
    "holt_m.optimal_beta = holt_m.model.model.params[\"smoothing_trend\"]\n",
    "print(f\"Alpha óptimo: {holt_m.optimal_alpha:.4f}\")\n",
    "print(f\"Beta óptimo: {holt_m.optimal_beta:.4f}\")\n",
    "holt_m.forecast = holt_m.model.forecast(steps=12)\n",
    "holt_m.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_d.model = Holt(train_data_days).fit(optimized=True)\n",
    "holt_d.optimal_alpha = holt_d.model.model.params[\"smoothing_level\"]\n",
    "holt_d.optimal_beta = holt_d.model.model.params[\"smoothing_trend\"]\n",
    "print(f\"Alpha óptimo: {holt_d.optimal_alpha:.4f}\")\n",
    "print(f\"Beta óptimo: {holt_d.optimal_beta:.4f}\")\n",
    "holt_d.forecast = holt_d.model.forecast(steps=366)\n",
    "holt_d.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt_h.model = Holt(train_data_hours).fit(optimized=True)\n",
    "holt_h.optimal_alpha = holt_h.model.model.params[\"smoothing_level\"]\n",
    "holt_h.optimal_beta = holt_h.model.model.params[\"smoothing_trend\"]\n",
    "print(f\"Alpha óptimo: {holt_h.optimal_alpha:.4f}\")\n",
    "print(f\"Beta óptimo: {holt_h.optimal_beta:.4f}\")\n",
    "holt_h.forecast = holt_h.model.forecast(steps=366*24)\n",
    "holt_h.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha\n",
    "holt_winters_m.model = ExponentialSmoothing(train_data_months, trend='add', seasonal='add', seasonal_periods=12).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "holt_winters_m.optimal_params = holt_winters_m.model.params\n",
    "print(f\"Parámetros óptimos: {holt_winters_m.optimal_params}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "holt_winters_m.forecast = holt_winters_m.model.forecast(steps=12)\n",
    "holt_winters_m.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha, seasonal period de 7 para intentar calcular una ciclidad semanal\n",
    "holt_winters_d.model = ExponentialSmoothing(train_data_days, trend='add', seasonal='add', seasonal_periods=7).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "holt_winters_d.optimal_params = holt_winters_d.model.params\n",
    "print(f\"Parámetros óptimos: {holt_winters_d.optimal_params}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "holt_winters_d.forecast = holt_winters_d.model.forecast(steps=366)\n",
    "holt_winters_d.forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar el modelo con cálculo óptimo de alpha, seasonal period de 24 para intentar calcular una ciclidad diaria\n",
    "holt_winters_h.model = ExponentialSmoothing(train_data_hours, trend='add', seasonal='add', seasonal_periods=24).fit(optimized=True)\n",
    "\n",
    "# Obtener el alpha óptimo\n",
    "holt_winters_h.optimal_params = holt_winters_h.model.params\n",
    "print(f\"Parámetros óptimos: {holt_winters_h.optimal_params}\")\n",
    "\n",
    "# Predicción a futuro (próximo año)\n",
    "holt_winters_h.forecast = holt_winters_h.model.forecast(steps=366*24)\n",
    "holt_winters_h.forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = os.getenv(\"MY_NIXTLA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nixtla_client = NixtlaClient(\n",
    "    api_key = my_api_key\n",
    ")\n",
    "nixtla_client.validate_api_key()\n",
    "\n",
    "timegpt_m.predictions = nixtla_client.predict(\n",
    "    df=train_data_months,\n",
    "    horizon=12,\n",
    "    time_col='DateTime',\n",
    "    target_col='Open',\n",
    ")\n",
    "\n",
    "timegpt_d.predictions = nixtla_client.predict(\n",
    "    df=train_data_days,\n",
    "    horizon=366,\n",
    "    time_col='DateTime',\n",
    "    target_col='Open',\n",
    ")\n",
    "\n",
    "timegpt_h.predictions = nixtla_client.predict(\n",
    "    df=train_data_hours,\n",
    "    horizon=366*24,\n",
    "    time_col='DateTime',\n",
    "    target_col='Open',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/SalesforceAIResearch/uni2ts/\n",
    "%pip install uni2ts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIZE = \"small\"  # model size: choose from {'small', 'base', 'large'}\n",
    "PDT = 20  # prediction length: any positive integer\n",
    "CTX = 200  # context length: any positive integer\n",
    "PSZ = \"auto\"  # patch size: choose from {\"auto\", 8, 16, 32, 64, 128}\n",
    "BSZ = 32  # batch size: any positive integer\n",
    "TEST = 100  # test set length: any positive integer\n",
    "\n",
    "# Convert into GluonTS dataset\n",
    "ds = PandasDataset(dict(df))\n",
    "\n",
    "# Split into train/test set\n",
    "train, test_template = split(\n",
    "    ds, offset=-TEST\n",
    ")  # assign last TEST time steps as test set\n",
    "\n",
    "# Construct rolling window evaluation\n",
    "test_data = test_template.generate_instances(\n",
    "    prediction_length=PDT,  # number of time steps for each prediction\n",
    "    windows=TEST // PDT,  # number of windows in rolling window evaluation\n",
    "    distance=PDT,  # number of time steps between each window - distance=PDT for non-overlapping windows\n",
    ")\n",
    "\n",
    "# Prepare pre-trained model by downloading model weights from huggingface hub\n",
    "model = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-{SIZE}\"),\n",
    "    prediction_length=PDT,\n",
    "    context_length=CTX,\n",
    "    patch_size=PSZ,\n",
    "    num_samples=100,\n",
    "    target_dim=1,\n",
    "    feat_dynamic_real_dim=ds.num_feat_dynamic_real,\n",
    "    past_feat_dynamic_real_dim=ds.num_past_feat_dynamic_real,\n",
    ")\n",
    "\n",
    "predictor = model.create_predictor(batch_size=BSZ)\n",
    "forecasts = predictor.predict(test_data.input)\n",
    "\n",
    "input_it = iter(test_data.input)\n",
    "label_it = iter(test_data.label)\n",
    "forecast_it = iter(forecasts)\n",
    "\n",
    "inp = next(input_it)\n",
    "label = next(label_it)\n",
    "forecast = next(forecast_it)\n",
    "\n",
    "plot_single(\n",
    "    inp, \n",
    "    label, \n",
    "    forecast, \n",
    "    context_length=200,\n",
    "    name=\"pred\",\n",
    "    show_label=True,\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la serie temporal a lenguaje natural\n",
    "desp = mpt.paraphrase_initial(gpt_m.name)\n",
    "train_lan = mpt.paraphrase_seq2lan(train_data_months, desp)\n",
    "\n",
    "# Realizar la predicción para los próximos 12 meses (1 año)\n",
    "steps = 12  # Número de meses a predecir\n",
    "model_name = 'gpt-4o-mini'  \n",
    "predicted_lan = mpt.paraphrasing_predict_llm(desp, train_lan, steps, model_name)\n",
    "print(predicted_lan)\n",
    "# Convertir la predicción en lenguaje natural de vuelta a una serie temporal\n",
    "predicted_series = mpt.recover_lan2seq(predicted_lan)\n",
    "\n",
    "# Mostrar la serie temporal predicha\n",
    "print(predicted_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "#login(token=HF_TOKEN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicde\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1010: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:08<00:00, 17.13s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Qué es el aprendizaje automático? El aprendizaje automático (AL) es un campo de la inteligencia artificial (IA) que se enfoca en el desarrollo de algoritmos y técnicas para que las computadoras puedan aprender de los datos y mejorar su rendimiento en tareas específicas sin ser programadas explícitamente. El objetivo principal del AL es que las máquinas puedan identificar patrones y relaciones en los datos, hacer predicciones, clasificar objetos, reconocer patrones y tomar decisiones basadas en los datos de entrenamiento.\n",
      "El aprendizaje automático se basa en la idea de que las computadoras pueden aprender de los datos de la misma manera que los seres humanos aprenden de la experiencia. Los algoritmos de aprendizaje automático se entrenan en grandes conjuntos de datos, que pueden incluir textos, imágenes, sonidos, etc. Una vez entrenados, los algoritmos pueden hacer predicciones o\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float32,   # usar float32 para CPU\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\"¿Qué es el aprendizaje automático?\", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=200)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
